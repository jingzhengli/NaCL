import sys
import os.path as osp
import time
import timm
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as T
from torch.utils.data import ConcatDataset

sys.path.append('../../..')
import common.vision.datasets as datasets

def get_dataset(dataset_name, root, source, target, train_source_transform, val_transform, train_target_transform=None):
    if train_target_transform is None:
        train_target_transform = train_source_transform
    if dataset_name == "Digits":
        train_source_dataset = datasets.__dict__[source[0]](osp.join(root, source[0]), download=True,
                                                            transform=train_source_transform)
        train_target_dataset = datasets.__dict__[target[0]](osp.join(root, target[0]), download=True,
                                                            transform=train_target_transform)
        val_dataset = test_dataset = datasets.__dict__[target[0]](osp.join(root, target[0]), split='test',
                                                                  download=True, transform=val_transform)
        class_names = datasets.MNIST.get_classes()
        num_classes = len(class_names)
    elif dataset_name in datasets.__dict__:
        # load datasets from common.vision.datasets
        dataset = datasets.__dict__[dataset_name]

        def concat_dataset(tasks, **kwargs):
            # return ConcatDataset([dataset(task=task, **kwargs) for task in tasks])
            return dataset(task=tasks, **kwargs)

        train_source_dataset = concat_dataset(root=root, tasks=source, download=True, transform=train_source_transform)
        train_target_dataset = concat_dataset(root=root, tasks=target, download=True, transform=train_target_transform)
        val_dataset = concat_dataset(root=root, tasks=target, download=True, transform=val_transform)
        if dataset_name == 'DomainNet':
            test_dataset = concat_dataset(root=root, tasks=target, split='test', download=True, transform=val_transform)
        else:
            test_dataset = val_dataset
        # class_names = train_source_dataset.datasets[0].classes
        num_classes = train_source_dataset.num_classes
        # num_classes = len(class_names)
        source_cluster_dataset= concat_dataset(root=root, tasks=source, download=True, transform=val_transform)
        target_cluster_dataset= concat_dataset(root=root, tasks=target, download=True, transform=val_transform)
    else:
        print('error data')
    return train_source_dataset, train_target_dataset, val_dataset, test_dataset,source_cluster_dataset, target_cluster_dataset, num_classes

